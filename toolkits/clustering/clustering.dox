	/**

\page clustering Clustering

This toolkit will contain implementations of clustering algorithm.

Currently the algorithms implemented are 

\li \ref clustering_kmeans "KMeans++"
\li \ref clustering_spectral_clustering "Spectral Clustering"


\section clustering_kmeans KMeans++

The \c kmeans program implements the 
<a href="http://en.wikipedia.org/wiki/K-means%2B%2B">KMeans++</a> algorithm described 
by 

Arthur, D. and Vassilvitskii, S. (2007). "k-means++: the advantages of careful seeding". 
Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. pp. 1027â€“1035.

It takes as input a collection of files where each line in each file represents
a data point.  Each line must contains a list of numbers, white-space or comma
separated. Each line must be the same length. 

For instance in this example input file, there are 6 datapoints, one per line,
and each datapoint is a point in a 5-dimensional space.  

\verbatim
-10.7551  6.82178 5.33455 -2.08247  2.86694 
-1.36687  10.8464 -5.28851  -4.26768  -5.50659  
-8.79834  8.01002 5.33418 0.102824  3.23318 
-8.64345  6.81946 1.2309  -4.46784  2.26341 
-8.29782  7.1154  3.32559 -2.59422  2.33936 
-8.12504  8.98924 4.15027 0.253153  1.75911 
\endverbatim

\subsection clustering_kmeans_synthetic Synthetic Data
Example synthetic data can be generated by running

\verbatim
> ./generate_synthetic [Number of Clusters] [Number of Dimensions] [Number of datapoints]
\endverbatim

This will generate a file called \c synthetic.txt , and will also output to screen
the cluster centers.

For instance:
\verbatim
> ./generate_synthetic 2 3 10
Usage: generate_synthetic [NClusters] [Dimensions] [Ndata]
Center 0 at: -6.69675 0.355189  -4.88601  
Center 1 at: 5.85919  0.0388327 5.50007  

> cat synthetic.txt
-4.31568  -0.396959 -6.29507  
-4.56112  -1.74917  -4.57874  
4.54508 0.102845  6.35385 
4.87746 -0.832591 7.06942 
-5.91254  -0.278006 -4.25934  
6.95139 0.120139  4.89531 
-6.28538  -0.88527  -4.74988  
-6.84791  0.887664  -4.91919  
7.47117 1.67911 6.02221 
-4.78011  1.2099  -4.55519  
\endverbatim

\note Mathematically, the synthetic generator draws centers from the [-10,10]^D
uniform hypercube and draws data points by sampling uniformly from the centers,
and around a unit gaussian around each center.


\subsection clustering_kmeans_running Running KMeans
To run Kmeans clustering:
\verbatim
> ./kmeans --data=[data prefix] --cluster=[N cluster] --output-clusters=[cluster output file]
\endverbatim

All files beginning with the data prefix will be loaded. The data may be on
HDFS.  The \c --cluster option is the number of clusters to solve for.

The cluster output file must be a target accessible on the local file system.
(In the distributed case, it must be accessible from the 0th machine).
This file will contain a list of all the solved cluster centers.

For instance, running on the synthetic data above:
\verbatim
>./kmeans --data=synthetic.txt --clusters=2 --output-clusters=cluster.txt
Number of datapoints: 10
Validating data...Initializing using Kmeans++
Running Kmeans...
Kmeans iteration 1: # points with changed assignments = 0
Writing Cluster Centers...

>cat cluster.txt
-5.45046  -0.201973 -4.8929 
5.96127 0.267376  6.0852  
\endverbatim


To also output the cluster center assignments for each datapoint,
add the option:
\verbatim
--output-data=[output prefix]
\endverbatim

Tne <tt>output prefix</tt> is where the output data will be written. This
may be located on HDFS. For instance, if the <tt>output_prefix</tt> is <tt>"v_out"</tt>,
the output files will be written to:

\verbatim
v_out_1_of_16
v_out_2_of_16
...
v_out_16_of_16
\endverbatim

Each line in the output files contain firstly, the original data point, followed
$by the cluster number it was assigned to. These need not be in the same order
as the original input.

For instance, running kmeans on the example synthetic data above may produce
the following output:

\verbatim
>./kmeans --data=synthetic.txt --clusters=2 --output-clusters=cluster.txt --output-data=data.txt
Number of datapoints: 10
Validating data...Initializing using Kmeans++
Running Kmeans...
Kmeans iteration 1: # points with changed assignments = 0
Writing Cluster Centers...
Writing Data with cluster assignments...

>cat data.txt
-4.78011  1.2099  -4.55519  0
7.47117 1.67911 6.02221 1
-6.84791  0.887664  -4.91919  0
-6.28538  -0.88527  -4.74988  0
6.95139 0.120139  4.89531 1
-5.91254  -0.278006 -4.25934  0
4.87746 -0.832591 7.06942 1
4.54508 0.102845  6.35385 1
-4.56112  -1.74917  -4.57874  0
-4.31568  -0.396959 -6.29507  0
\endverbatim

This program can also run distributed by using
\verbatim
> mpiexec -n [N machines] --hostfile [host file] ./kmeans ....
\endverbatim
See your MPI documentation for details on how to launch this job.
All machines must have access to the input graph location and the output graph 
location. Graphs may be on HDFS. 
If you have problems loading HDFS files, see the \ref FAQ.


\subsection clustering_kmeans_sparse --sparse Option

If <tt>--sparse=1</tt> is set (default is 0), the program will use 
a sparse vector representation. 
The file format is [feature id]:[value] [feature id]:[value] ...
Each line corresponds to a datapoint.
[feature id] must be positive integer or zero.

For instance:
\verbatim
> cat synthetic_sparse.txt
0:-4.31568  3:-0.396959 5:-6.29507  
5:-4.56112  9:-1.74917  
4:4.54508 5:0.102845  10:6.35385 
0:4.87746 7:-0.832591 
\endverbatim


\subsection clustering_kmeans_id --id Option

If <tt>--id=1</tt> is set (default is 0), the program will use 
id for each data point. The id of a data point must be written at the head 
of each line of the input data.

For instance:
\verbatim
> cat synthetic_with_id.txt
1 -4.31568  -0.396959 -6.29507  
2 -4.56112  -1.74917  -4.57874  
3 4.54508 0.102845  6.35385 
4 4.87746 -0.832591 7.06942 
\endverbatim

The output data will consist of two columns: one for the ids and the other for 
the assigned clusters.

For instance:
\verbatim
> cat data_with_id.txt
1 0
2 0  
3 1
4 1 
\endverbatim

<tt>--id</tt> can be used with <tt>--sparse</tt>.

\subsection clustering_kmeans_edge_data Adding Pairwise Reward

This program can consider pairwise rewards (and penalty) by using 
<tt>--pairwise-reward=[file prefix]</tt>. All files beginning with 
<tt>[file prefix]</tt> will be loaded for pairwise rewards. Each 
line of the pairwise reward file holds [id1] [id2] [weight].
This option must be used with <tt>--id=1</tt>.
 
For instance:
\verbatim
> cat pairwise_data.txt
1 2 10
2 4 -10
\endverbatim

In this example the evaluation function will gain 10 when data <tt>1</tt> 
and data <tt>2</tt> are in the same cluster; it will gain nothing otherwise.


\subsection clustering_kmeans_options Options
\li \b --data (Required). The prefix from which to load the input data
\li \b --clusters (Required). The number of cluster centers
\li \b --ncpus (Optional. Default 2) The number of processors that will be used
for computation. <b>Due to some implementation limitations within GraphLab,
   this parameter is not respected. It will use all processors on your machine
   if ran in Linux, and will use only 1 processor if ran on Mac</b> 
\li \b --output-data  (Optional) A target prefix to write the output data 
   with cluster assignments. May be on HDFS.
\li \b --output-clusters (Optional) A target location to write the cluster centers.
   Must be on the local file system.
\li \b --sparse (Optional. Default 0) If set at 1, will use sparse vector representation
\li \b --id (Optional. Default 0) If set at 1, will use ids for data points
\li \b --pairwise-reward (Optional) If set, will consider pairwise rewards written in the 
   files beginning with the given argument
\li \b --max-iteration (Optional) The max number of iterations







\section clustering_spectral_clustering Spectral Clustering

This program takes as input a collection of files where each line in each file represents 
a data point. Each line must contains an id and a list of numbers, white-space or comma 
separated. Each line must be the same length. 
For instance in this example input file, there are 6 datapoints, one per line,
and each datapoint is a point in a 5-dimensional space.  

\verbatim
1 -10.7551  6.82178 5.33455 -2.08247  2.86694
2 -1.36687  10.8464 -5.28851  -4.26768  -5.50659
3 -8.79834  8.01002 5.33418 0.102824  3.23318 
4 -8.64345  6.81946 1.2309  -4.46784  2.26341 
5 -8.29782  7.1154  3.32559 -2.59422  2.33936
6 -8.12504  8.98924 4.15027 0.253153  1.75911 
\endverbatim

The ids of data points must start from 1 and must not skip any numbers.

To run spectral clustering, the minimal set of options required are:

\verbatim
> ./spectral_clustering --data=[data prefix] --clusters=[N cluster]
\endverbatim

This program uses svd in Graphlab Collaborative Filtering Toolkit, 
kmeans in Graphlab Clustering Toolkit and eigen_vector_normalization in 
Graphlab Graph Analytics Toolkit.  The paths to the directories are
specified by <tt>--svd-dir</tt>, <tt>--kmeans-dir</tt> and 
<tt>--graph-analytics-dir</tt>, respectively.

The program will create some intermediate files. The final clustering
result is written in files named <tt>[data prefix].result</tt> with a suffix,
for example <tt>[data prefix].result_1_of_4</tt>. The clustering result
data will consist of two columns: one for the ids and the other for the
assigned clusters. For instance:

\verbatim
1 1
2 0
3 1
4 1
5 1
\endverbatim

<b>NOTE:</b> To run the spectral clustering in a distributed setting, you must use the 
"mpi-args" option, not like other graphlab toolkits. 
The spectral clustering calls other graphlab programs.
When "--mpi-args" is set, these graphlab programs are called with "mpiexec" and the 
string written after the "mpi-args" option.
For example, if you set --mpi-args="-n 4 --hostfile host", the program calls the 
other graphlab programs with "mpiexec -n 4 --hostfile host".

\subsection Options
Relevant options are:
\li \b --data (Required). The prefix from which to load the input data
\li \b --clusters (Required). The number of clusters
\li \b --sigma (Optional. Default 0.1). Scale parameter for Gaussian kernel.
This value is often critical to the clustering result.
\li \b --t-nearest (Optional. Default 20). Number of nearest neighbors (=t). 
Will use only the t-nearest similarities for each datapoint. If set at 0,
will use all similarities. 
\li \b --similarity-thres (Optional). Threshold to discard small similarities.
If a value is set, similarities less than this value will be discarded.
\li \b --svd-dir (Optional Default ../collaborative_filtering/).
Path to the directory where Graphlab svd is located
\li \b --kmeans-dir (Optional. Default ../clustering/). 
Path to the directory where Graphlab kmeans is located
\li \b --graph-analytics-dir (Optional. Default ../graph_analytics/).
Path to the directory where Graphlab eigen_vector_normalization is located
\li \b --ncpus (Optional. Default 2). The number of processors that will be used for computation. 
<b>Due to some implementation limitations within GraphLab, 
this parameter is not respected. It will use all processors on your machine 
if ran in Linux, and will use only 1 processor if ran on Mac</b> 
\li \b --graph_opts (Optional, Default empty). Any additional graph options. See
  graphlab::distributed_graph a list of options.
\li \b --mpi-args (Optional, Default empty). If set, will execute mipexec with the given string.


*/


